The OpenNebula Front-end connects to the hypervisor Hosts using SSH. Following connection types are being established:

- from Front-end to Front-end,
- from Front-end to hypervisor Host,
- from Front-end to hypervisor Host with another connection within to another Host (for migration operations),
- from Front-end to hypervisor Host with another connection within back to Front-end (for data copy back).

.. important::

    It must be ensured that Front-end and all Hosts **can connect to each other** over SSH without manual intervention.

When OpenNebula server package is installed on the Front-end, a SSH key pair is automatically generated for the *oneadmin* user into ``/var/lib/one/.ssh/id_rsa`` and ``/var/lib/one/.ssh/id_rsa.pub``, the public key is also added into ``/var/lib/one/.ssh/authorized_keys``. It happens only if these files don't exist yet, existing files (e.g., leftovers from previous installations) are not touched! For new installations, the :ref:`default SSH configuration <node_ssh_config>` is placed for the *oneadmin* from ``/usr/share/one/ssh`` into ``/var/lib/one/.ssh/config``.

To enable passwordless connections you must distribute the public key of the *oneadmin* user from the Front-end to ``/var/lib/one/.ssh/authorized_keys`` on all hypervisor Hosts. There are many methods to achieve the distribution of the SSH keys. Ultimately the administrator should choose a method; the recommendation is to use a configuration management system (e.g., Ansible or Puppet). In this guide, we are going to manually use SSH tools.

**Since OpenNebula 5.12**. On the Front-end runs dedicated **SSH authentication agent** service which imports the *oneadmin*'s private key on its start. Access to this agent is delegated (forwarded) from the OpenNebula Front-end to the hypervisor Hosts for the operations which need to connect between Hosts or back to the Front-end. While the authentication agent is used, you **don't need to distribute private SSH key from Front-end** to hypervisor Hosts!

To learn more about the SSH, read the :ref:`Advanced SSH Usage <node_ssh>` guide.

A. Populate Host SSH Keys
-------------------------

You should prepare and further manage the list of host SSH public keys of your nodes (a.k.a. ``known_hosts``) so that all communicating parties know the identity of the other sides. The file is located in ``/var/lib/one/.ssh/known_hosts`` and we can use the command ``ssh-keyscan`` to manually create it. It should be executed on your Front-end under *oneadmin* user and copied on all your Hosts.

.. important::

   You'll need to update and redistribute file with host keys every time any host is reinstalled or its keys are regenerated.

.. important::

   If :ref:`default SSH configuration <node_ssh_config>` shipped with OpenNebula is used, the SSH client automatically accepts host keys on the first connection. That makes this step optional, as the ``known_hosts`` will be incrementally automatically generated on your infrastructure when the various connections happen. While this simplifies the initial deployment, it lowers the security of your infrastructure. We highly recommend to populate ``known_hosts`` on your infrastructure in controlled manner!

Make sure you are logged on your Front-end and run the commands as *oneadmin*, e.g. by typing:

.. prompt:: bash $ auto

    # su - oneadmin

Create the ``known_hosts`` file by running following command with all the Host names including the Front-end as parameters:

.. prompt:: bash $ auto

    $ ssh-keyscan <frontend> <node1> <node2> <node3> ... >> /var/lib/one/.ssh/known_hosts

B. Distribute Authentication Configuration
------------------------------------------

To enable passwordless login on your infrastructure, you must copy authentication configuration for *oneadmin* user from Front-end to all your nodes. We'll distribute only ``known_hosts`` created in the previous section and *oneadmin*'s SSH public key from Front-end to your nodes. We **don't need to distribute oneadmin's SSH private key** from Front-end, as it'll be securely delegated from Front-end to hypervisor Hosts with the default **SSH authentication agent** service running on the Front-end.

Make sure you are logged on your Front-end and run the commands as *oneadmin*, e.g. by typing:

.. prompt:: bash $ auto

    # su - oneadmin

Enable passwordless logins by executing the following command for each your Host. For example:

.. prompt:: bash $ auto

    $ ssh-copy-id -i /var/lib/one/.ssh/id_rsa.pub <node1>
    $ ssh-copy-id -i /var/lib/one/.ssh/id_rsa.pub <node2>
    $ ssh-copy-id -i /var/lib/one/.ssh/id_rsa.pub <node3>

If the list of host SSH public keys was created in the previous section, distribute the ``known_hosts`` file on each your Host. For example:

.. prompt:: bash $ auto

    $ scp -p /var/lib/one/.ssh/known_hosts <node1>:/var/lib/one/.ssh/
    $ scp -p /var/lib/one/.ssh/known_hosts <node2>:/var/lib/one/.ssh/
    $ scp -p /var/lib/one/.ssh/known_hosts <node3>:/var/lib/one/.ssh/

Without SSH Authentication Agent (Optional)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. warning::

    **Not Recommended**. If you don't use integrated SSH authentication agent service (which is initially enabled) on the Front-end, you'll have to distribute also *oneadmin*'s private SSH key on your hypervisor Hosts to allow connections among Hosts and from Hosts to Front-end. For security reasons, it's recommended to use SSH authentication agent service and **avoid this step**.

    If you need to distribute *oneadmin*'s private SSH key on your Hosts, proceeed with steps above and continue with following extra commands for all your Hosts. For example:

    .. prompt:: bash $ auto

        $ scp -p /var/lib/one/.ssh/id_rsa <node1>:/var/lib/one/.ssh/
        $ scp -p /var/lib/one/.ssh/id_rsa <node2>:/var/lib/one/.ssh/
        $ scp -p /var/lib/one/.ssh/id_rsa <node3>:/var/lib/one/.ssh/

C. Validate Connections
-----------------------

You should verify that none of these connections (under user *oneadmin*) fail and none require password:

* from the Front-end to Front-end itself
* from the Front-end to all Hosts
* from all Hosts to all Hosts
* from all Hosts back to Front-end

For example, execute on the Front-end:

.. prompt:: bash $ auto

    # from Front-end to Front-end itself
    $ ssh <frontend>
    $ exit

    # from Front-end to node, back to Front-end and to other nodes
    $ ssh <node1>
    $ ssh <frontend>
    $ exit
    $ ssh <node2>
    $ exit
    $ ssh <node3>
    $ exit
    $ exit

    # from Front-end to node, back to Front-end and to other nodes
    $ ssh <node2>
    $ ssh <frontend>
    $ exit
    $ ssh <node1>
    $ exit
    $ ssh <node3>
    $ exit
    $ exit

    # from Front-end to nodes and back to Front-end and other nodes
    $ ssh <node3>
    $ ssh <frontend>
    $ exit
    $ ssh <node1>
    $ exit
    $ ssh <node2>
    $ exit
    $ exit
